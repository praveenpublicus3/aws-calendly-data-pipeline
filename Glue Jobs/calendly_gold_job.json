{
	"jobConfig": {
		"name": "calendly_gold_job",
		"description": "",
		"role": "arn:aws:iam::647132523501:role/glue-s3-role-calendly",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "calendly_gold_job.py",
		"scriptLocation": "s3://aws-glue-assets-647132523501-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-10-30T11:01:17.323Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-647132523501-us-east-1/temporary/",
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-647132523501-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"dag": {},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.context import SparkContext
from pyspark.sql import functions as F

args = getResolvedOptions(sys.argv, ['JOB_NAME'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# --------------------------------------------
# 1️⃣  Calendly Summary  (Existing Logic)
# --------------------------------------------
silver_path = "s3://marketing-calendly-project/silver/calendly/"
silver_df = glueContext.create_dynamic_frame.from_options(
    connection_type="s3",
    connection_options={"paths": [silver_path]},
    format="parquet"
)
df = silver_df.toDF()

df_summary = df.groupBy("invitee_email", "event").agg(
    F.count("*").alias("total_invites")
)

gold_summary_path = "s3://marketing-calendly-project/gold/calendly_summary/"
df_summary.write.mode("overwrite").parquet(gold_summary_path)

# --------------------------------------------
# 2️⃣  Spend Table (Flatten Array)
# --------------------------------------------
try:
    spend_path = "s3://marketing-calendly-project/silver/spend/"
    spend_df = glueContext.create_dynamic_frame.from_options(
        connection_type="s3",
        connection_options={"paths": [spend_path]},
        format="parquet"
    ).toDF()

    # Some files have one column "array" -> flatten it if exists
    if "array" in spend_df.columns:
        spend_flat = spend_df.selectExpr("inline(array)")
    else:
        spend_flat = spend_df

    # Write flattened spend data to Gold
    gold_spend_path = "s3://marketing-calendly-project/gold/spend/"
    spend_flat.write.mode("overwrite").parquet(gold_spend_path)

    print("✅ Spend data flattened and written to Gold zone successfully")

except Exception as e:
    print(f"⚠️ Spend data step skipped or failed: {e}")

# --------------------------------------------
# 3️⃣  Landing Table (If Available)
# --------------------------------------------
try:
    landing_path = "s3://marketing-calendly-project/silver/landing/"
    landing_df = glueContext.create_dynamic_frame.from_options(
        connection_type="s3",
        connection_options={"paths": [landing_path]},
        format="parquet"
    ).toDF()

    # Optional cleanup or renaming if needed
    # Example: ensure column names are consistent
    landing_df_clean = landing_df.toDF(*[c.lower().strip() for c in landing_df.columns])

    gold_landing_path = "s3://marketing-calendly-project/gold/landing/"
    landing_df_clean.write.mode("overwrite").parquet(gold_landing_path)

    print("✅ Landing data written to Gold zone successfully")

except Exception as e:
    print(f"⚠️ Landing data step skipped or failed: {e}")

# --------------------------------------------
# Finalize
# --------------------------------------------
job.commit()"
